{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c4f5b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002468DCF79D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import cv2                       \n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import os\n",
    "\n",
    "model = load_model('model_file.h5')\n",
    "\n",
    "faceDetect = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') #Pre-trained classifier for face detection\n",
    "\n",
    "#faceDetect = cv2.CascadeClassifier(os.path.join(cv2.data.haarcascades, 'haarcascade_frontalface_default.xml'))\n",
    "\n",
    "labels_dict = {0:'Angry', 1:'Disgust',2:'Fear',3:'Happy',4:'Neutral',5:'Sad',6:'Surprise'}\n",
    "\n",
    "frame = cv2.imread(\"test2.jpeg\")\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "faces = faceDetect.detectMultiScale(gray,1.3,3)   #Detect all faces. gray: input parameter, 1.3: scaling factor, 3: minimum neighbours\n",
    "\n",
    "#faces detect are returned as 4 coordinates\n",
    "for x,y,w,h in faces:\n",
    "    sub_face_img = gray[y:y+h, x:x+w]\n",
    "    resized = cv2.resize(sub_face_img,(48,48))   #resizing our input image as our model is trained for 48x48 images\n",
    "    normalize = resized/255.0                    #Normalize\n",
    "    reshaped = np.reshape(normalize, (1,48,48,1)) #1: number of image, 48: image height, 48: image width, 1: Gray scale \n",
    "    result = model.predict(reshaped)\n",
    "    label = np.argmax(result, axis=1)[0]\n",
    "    print(label)\n",
    "    #Creating rectangle over face\n",
    "    cv2.rectangle(frame, (x,y), (x+w,y+h), (0,0,255), 1)  #(0,0,255) = BGR. Colour of rectangele is red. 1 is the thickness of rectagle\n",
    "    cv2.rectangle(frame, (x,y), (x+w,y+h), (50,50,255), 2)\n",
    "    cv2.rectangle(frame, (x,y-40), (x+w,y), (50,50,255), -1)\n",
    "    cv2.putText(frame,labels_dict[label], (x,y-10), cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,2))\n",
    "\n",
    "\n",
    "cv2.imshow(\"Frame\",frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8f75a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
